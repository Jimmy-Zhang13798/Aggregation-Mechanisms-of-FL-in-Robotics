{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jizhi\\.conda\\envs\\flv1\\python.exe\n",
      "3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\n",
      "True\n",
      "Torchvision version: 0.16.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "import copy\n",
    "import gc\n",
    "# draw metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import AlexNet_Weights\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.backends.cudnn.benchmark=True\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(torch.cuda.is_available())\n",
    "print(f'Torchvision version: {torchvision.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_value = 42\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logger\n",
    "# create logger\n",
    "logger = logging.getLogger(__name__)\n",
    "# set log level for all handlers to debug\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "# best for development or debugging\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s-%(levelname)s: %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "consoleHandler.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Hyperparameters for federated learning #########\n",
    "epochs_ = 50\n",
    "batch_size_ = 16\n",
    "writer_ = SummaryWriter('runs\\\\sim-fusion-alexnet\\\\')\n",
    "\n",
    "# CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "train_names_list = ['hospital','sim-room','warehouse']\n",
    "\n",
    "val_names_list = ['hospital','sim-room','warehouse','overall']\n",
    "\n",
    "train_data_folders_list = [ 'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\for_Centered_learning\\\\hospital_sim-room\\\\train',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\for_Centered_learning\\\\hospital_warehouse\\\\train',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\for_Centered_learning\\\\sim-room_warehouse\\\\train',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\for_Centered_learning\\\\hospital_sim-room_warehouse\\\\train',\n",
    "                    ]\n",
    "\n",
    "val_data_folders_list = [ 'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\hospital\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\sim-room\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\warehouse\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\overall\\\\test',\n",
    "                    ]\n",
    "\n",
    "transformed_train_datasets, transformed_val_datasets = [], []\n",
    "################################################  Data Loaders  #####################################\n",
    "# 在这个部分，为训练和验证的图像数据定义了一些预处理步骤，包括颜色抖动、重新调整大小、转换为张量和归一化。\n",
    "# 这些预处理步骤通过 PyTorch 的 transforms 模块实现，并且它们将在训练过程中应用到每个图像上。\n",
    "for train_dataset in train_data_folders_list:\n",
    "    transformed_train_datasets.append(\n",
    "        datasets.ImageFolder(\n",
    "            train_dataset,\n",
    "            transforms.Compose([\n",
    "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        )\n",
    "    ) \n",
    "\n",
    "for val_dataset in val_data_folders_list:\n",
    "    transformed_val_datasets.append(\n",
    "        datasets.ImageFolder(\n",
    "            val_dataset,\n",
    "            transforms.Compose([\n",
    "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        )\n",
    "    ) \n",
    "\n",
    "#########  Data Loaders  ##########\n",
    "\n",
    "train_loader_list, val_loader_list = [], []\n",
    "\n",
    "for train_d in transformed_train_datasets:\n",
    "    train_loader_list.append(\n",
    "        torch.utils.data.DataLoader(\n",
    "                train_d,\n",
    "                batch_size=batch_size_,\n",
    "                shuffle=True,\n",
    "                num_workers=4,\n",
    "                drop_last = False,\n",
    "            )\n",
    "    )\n",
    "\n",
    "for val_d in transformed_val_datasets:\n",
    "    val_loader_list.append(\n",
    "        torch.utils.data.DataLoader(\n",
    "                val_d,\n",
    "                batch_size=1,\n",
    "                shuffle=True,\n",
    "                num_workers=4,\n",
    "                drop_last = False,\n",
    "            )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model_name, writer, current_epoch, model, test_loader):\n",
    "    \"\"\"\n",
    "    This function test the global model on test \n",
    "    data and returns test loss and test accuracy \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    #test_loss = 0\n",
    "    #correct = 0\n",
    "    test_error_count1 = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:#以batch为单位取值\n",
    "            image, label = image.cuda(), label.cuda()\n",
    "            outputs = model(image)\n",
    "\n",
    "            test_error_count1 += float(torch.sum(torch.abs(label - outputs.argmax(1))))\n",
    "        # 用于计算测试阶段的平均损失\n",
    "        #test_loss /= len(test_loader.dataset)\n",
    "\n",
    "\n",
    "        acc = 1.0 - float(test_error_count1) / float(len(test_loader.dataset))\n",
    "        writer.add_scalar(\"Val-Acc/\"+model_name, acc, current_epoch)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\jizhi/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:21<00:00, 11.4MB/s] \n",
      "2023-11-02 18:26:54,163-INFO: -----------------------Start--------------------------\n",
      "2023-11-02 18:27:38,540-INFO: Centered Learning Model:hospital_sim-room, Epoch:0, Val_Data:overall, Accuracy:0.9735576923076923.\n",
      "2023-11-02 18:28:21,713-INFO: Centered Learning Model:hospital_sim-room, Epoch:1, Val_Data:overall, Accuracy:0.8774038461538461.\n",
      "2023-11-02 18:29:04,070-INFO: Centered Learning Model:hospital_sim-room, Epoch:2, Val_Data:overall, Accuracy:0.9014423076923077.\n",
      "2023-11-02 18:29:46,316-INFO: Centered Learning Model:hospital_sim-room, Epoch:3, Val_Data:overall, Accuracy:0.8774038461538461.\n",
      "2023-11-02 18:30:28,268-INFO: Centered Learning Model:hospital_sim-room, Epoch:4, Val_Data:overall, Accuracy:0.8677884615384616.\n",
      "2023-11-02 18:31:09,978-INFO: Centered Learning Model:hospital_sim-room, Epoch:5, Val_Data:overall, Accuracy:0.8894230769230769.\n",
      "2023-11-02 18:31:52,523-INFO: Centered Learning Model:hospital_sim-room, Epoch:6, Val_Data:overall, Accuracy:0.8485576923076923.\n",
      "2023-11-02 18:32:34,141-INFO: Centered Learning Model:hospital_sim-room, Epoch:7, Val_Data:overall, Accuracy:0.8461538461538461.\n",
      "2023-11-02 18:33:15,066-INFO: Centered Learning Model:hospital_sim-room, Epoch:8, Val_Data:overall, Accuracy:0.8461538461538461.\n",
      "2023-11-02 18:33:57,728-INFO: Centered Learning Model:hospital_sim-room, Epoch:9, Val_Data:overall, Accuracy:0.8293269230769231.\n",
      "2023-11-02 18:34:38,872-INFO: Centered Learning Model:hospital_sim-room, Epoch:10, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:35:19,526-INFO: Centered Learning Model:hospital_sim-room, Epoch:11, Val_Data:overall, Accuracy:0.84375.\n",
      "2023-11-02 18:36:02,449-INFO: Centered Learning Model:hospital_sim-room, Epoch:12, Val_Data:overall, Accuracy:0.84375.\n",
      "2023-11-02 18:36:44,043-INFO: Centered Learning Model:hospital_sim-room, Epoch:13, Val_Data:overall, Accuracy:0.8341346153846154.\n",
      "2023-11-02 18:37:24,899-INFO: Centered Learning Model:hospital_sim-room, Epoch:14, Val_Data:overall, Accuracy:0.8365384615384616.\n",
      "2023-11-02 18:38:05,335-INFO: Centered Learning Model:hospital_sim-room, Epoch:15, Val_Data:overall, Accuracy:0.8461538461538461.\n",
      "2023-11-02 18:38:47,753-INFO: Centered Learning Model:hospital_sim-room, Epoch:16, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:39:30,873-INFO: Centered Learning Model:hospital_sim-room, Epoch:17, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:40:14,143-INFO: Centered Learning Model:hospital_sim-room, Epoch:18, Val_Data:overall, Accuracy:0.8341346153846154.\n",
      "2023-11-02 18:41:00,918-INFO: Centered Learning Model:hospital_sim-room, Epoch:19, Val_Data:overall, Accuracy:0.8293269230769231.\n",
      "2023-11-02 18:41:48,030-INFO: Centered Learning Model:hospital_sim-room, Epoch:20, Val_Data:overall, Accuracy:0.8461538461538461.\n",
      "2023-11-02 18:42:33,532-INFO: Centered Learning Model:hospital_sim-room, Epoch:21, Val_Data:overall, Accuracy:0.8485576923076923.\n",
      "2023-11-02 18:43:19,275-INFO: Centered Learning Model:hospital_sim-room, Epoch:22, Val_Data:overall, Accuracy:0.8317307692307692.\n",
      "2023-11-02 18:44:05,227-INFO: Centered Learning Model:hospital_sim-room, Epoch:23, Val_Data:overall, Accuracy:0.8317307692307692.\n",
      "2023-11-02 18:44:50,895-INFO: Centered Learning Model:hospital_sim-room, Epoch:24, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:45:36,637-INFO: Centered Learning Model:hospital_sim-room, Epoch:25, Val_Data:overall, Accuracy:0.8557692307692308.\n",
      "2023-11-02 18:46:23,140-INFO: Centered Learning Model:hospital_sim-room, Epoch:26, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:47:09,099-INFO: Centered Learning Model:hospital_sim-room, Epoch:27, Val_Data:overall, Accuracy:0.8509615384615384.\n",
      "2023-11-02 18:47:54,536-INFO: Centered Learning Model:hospital_sim-room, Epoch:28, Val_Data:overall, Accuracy:0.8629807692307692.\n",
      "2023-11-02 18:48:40,321-INFO: Centered Learning Model:hospital_sim-room, Epoch:29, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 18:49:26,317-INFO: Centered Learning Model:hospital_sim-room, Epoch:30, Val_Data:overall, Accuracy:0.8485576923076923.\n",
      "2023-11-02 18:50:11,861-INFO: Centered Learning Model:hospital_sim-room, Epoch:31, Val_Data:overall, Accuracy:0.8581730769230769.\n",
      "2023-11-02 18:50:57,648-INFO: Centered Learning Model:hospital_sim-room, Epoch:32, Val_Data:overall, Accuracy:0.8509615384615384.\n",
      "2023-11-02 18:51:43,290-INFO: Centered Learning Model:hospital_sim-room, Epoch:33, Val_Data:overall, Accuracy:0.8485576923076923.\n",
      "2023-11-02 18:52:29,049-INFO: Centered Learning Model:hospital_sim-room, Epoch:34, Val_Data:overall, Accuracy:0.8173076923076923.\n",
      "2023-11-02 18:53:14,492-INFO: Centered Learning Model:hospital_sim-room, Epoch:35, Val_Data:overall, Accuracy:0.8485576923076923.\n",
      "2023-11-02 18:54:00,346-INFO: Centered Learning Model:hospital_sim-room, Epoch:36, Val_Data:overall, Accuracy:0.8245192307692308.\n",
      "2023-11-02 18:54:45,831-INFO: Centered Learning Model:hospital_sim-room, Epoch:37, Val_Data:overall, Accuracy:0.7980769230769231.\n",
      "2023-11-02 18:55:31,511-INFO: Centered Learning Model:hospital_sim-room, Epoch:38, Val_Data:overall, Accuracy:0.8293269230769231.\n",
      "2023-11-02 18:56:18,570-INFO: Centered Learning Model:hospital_sim-room, Epoch:39, Val_Data:overall, Accuracy:0.8341346153846154.\n",
      "2023-11-02 18:57:04,970-INFO: Centered Learning Model:hospital_sim-room, Epoch:40, Val_Data:overall, Accuracy:0.8269230769230769.\n",
      "2023-11-02 18:57:50,614-INFO: Centered Learning Model:hospital_sim-room, Epoch:41, Val_Data:overall, Accuracy:0.8221153846153846.\n",
      "2023-11-02 18:58:36,473-INFO: Centered Learning Model:hospital_sim-room, Epoch:42, Val_Data:overall, Accuracy:0.8221153846153846.\n",
      "2023-11-02 18:59:21,976-INFO: Centered Learning Model:hospital_sim-room, Epoch:43, Val_Data:overall, Accuracy:0.8293269230769231.\n",
      "2023-11-02 19:00:07,552-INFO: Centered Learning Model:hospital_sim-room, Epoch:44, Val_Data:overall, Accuracy:0.8317307692307692.\n",
      "2023-11-02 19:00:53,288-INFO: Centered Learning Model:hospital_sim-room, Epoch:45, Val_Data:overall, Accuracy:0.8245192307692308.\n",
      "2023-11-02 19:01:38,980-INFO: Centered Learning Model:hospital_sim-room, Epoch:46, Val_Data:overall, Accuracy:0.8341346153846154.\n",
      "2023-11-02 19:02:25,005-INFO: Centered Learning Model:hospital_sim-room, Epoch:47, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 19:03:11,171-INFO: Centered Learning Model:hospital_sim-room, Epoch:48, Val_Data:overall, Accuracy:0.8581730769230769.\n",
      "2023-11-02 19:03:56,943-INFO: Centered Learning Model:hospital_sim-room, Epoch:49, Val_Data:overall, Accuracy:0.8413461538461539.\n",
      "2023-11-02 19:03:56,948-INFO: Final Centered Learning Model:hospital_sim-room, Best Accuracy:0.9735576923076923.\n",
      "2023-11-02 19:03:56,950-INFO: DONE!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "model = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 这行代码修改了AlexNet模型分类器的最后一层。它将最后一层的输出特征数从原始的1000（AlexNet在ImageNet上的分类数）改为了2。\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optims_=optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "logger.info(\"-----------------------Start--------------------------\")\n",
    "\n",
    "#这行代码创建了一个梯度缩放器，它通常用于半精度（float16）训练，这可以加速训练并减少GPU内存使用。如果你不打算使用半精度训练，这个部分可以忽略。\n",
    "scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "\n",
    "best_acc = 0.0\n",
    "for i in range(epochs_):\n",
    "    for images, labels in train_loader_list[0]:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optims_.zero_grad()\n",
    "        with torch.cuda.amp.autocast_mode.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optims_)\n",
    "        scaler.update()\n",
    "\n",
    "    val_inx  = 3 #用overall数据集来决定最后存储的模型\n",
    "    val_data = val_loader_list[val_inx]\n",
    "\n",
    "    acc = test(\"Fusion_Models:hospital_sim-room-On-Val-Data-{}\".format(val_names_list[val_inx]), writer_, i, model,  val_data)\n",
    "    logger.info(\"Centered Learning Model:hospital_sim-room, Epoch:{}, Val_Data:{}, Accuracy:{}.\".format(i, val_names_list[val_inx], acc))\n",
    "\n",
    "    if acc > best_acc and acc < 1.0:\n",
    "        best_acc = acc\n",
    "        save_path = f\"C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_results\\\\saved_models\\\\sim\\\\fusion_models\\\\Centered_Learning_hospital_sim-room_center.pth\"\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "logger.info(\"Final Centered Learning Model:hospital_sim-room, Best Accuracy:{}.\".format(best_acc))\n",
    "\n",
    "logger.info(\"DONE!!!!!!!!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c33489c15c8996ec65adc4ce87c66b361d619ea135fc25c6686da34a5b53bcc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

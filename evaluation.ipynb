{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jizhi\\.conda\\envs\\flv1\\python.exe\n",
      "3.8.18 (default, Sep 11 2023, 13:39:12) [MSC v.1916 64 bit (AMD64)]\n",
      "True\n",
      "Torchvision version: 0.16.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef\n",
    "import csv\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.models as models\n",
    "from torchvision.models import AlexNet_Weights\n",
    "import torchmetrics\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.backends.cudnn.benchmark=True\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(torch.cuda.is_available())\n",
    "print(f'Torchvision version: {torchvision.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_value = 42\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logger\n",
    "# create logger\n",
    "logger = logging.getLogger(__name__)\n",
    "# set log level for all handlers to debug\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "# best for development or debugging\n",
    "consoleHandler = logging.StreamHandler()\n",
    "consoleHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s-%(levelname)s: %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "consoleHandler.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(consoleHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image\n",
    "train_names_list = ['hospital','sim-room','warehouse']\n",
    "\n",
    "val_names_list = ['hospital','sim-room','warehouse','overall']\n",
    "\n",
    "train_data_folders_list = [ 'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\hospital\\\\train',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\sim-room\\\\train',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\warehouse\\\\train',\n",
    "                    ]\n",
    "\n",
    "val_data_folders_list = [ 'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\hospital\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\sim-room\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\warehouse\\\\test',\n",
    "                            'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_data\\\\mine\\\\sim_train\\\\overall\\\\test',\n",
    "                    ]\n",
    "\n",
    "transformed_train_datasets, transformed_val_datasets = [], []\n",
    "\n",
    "################################################  Data Loaders  #####################################\n",
    "# 在这个部分，为训练和验证的图像数据定义了一些预处理步骤，包括颜色抖动、重新调整大小、转换为张量和归一化。\n",
    "# 这些预处理步骤通过 PyTorch 的 transforms 模块实现，并且它们将在训练过程中应用到每个图像上。\n",
    "for train_dataset in train_data_folders_list:\n",
    "    transformed_train_datasets.append(\n",
    "        datasets.ImageFolder(\n",
    "            train_dataset,\n",
    "            transforms.Compose([\n",
    "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        )\n",
    "    ) \n",
    "\n",
    "for val_dataset in val_data_folders_list:\n",
    "    transformed_val_datasets.append(\n",
    "        datasets.ImageFolder(\n",
    "            val_dataset,\n",
    "            transforms.Compose([\n",
    "                transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        )\n",
    "    ) \n",
    "\n",
    "#########  Data Loaders  ##########\n",
    "\n",
    "train_loader_list, val_loader_list = [], []\n",
    "\n",
    "for train_d in transformed_train_datasets:\n",
    "    train_loader_list.append(\n",
    "        torch.utils.data.DataLoader(\n",
    "                train_d,\n",
    "                batch_size=16,\n",
    "                shuffle=True,\n",
    "                num_workers=4,\n",
    "                drop_last = False,\n",
    "            )\n",
    "    )\n",
    "\n",
    "for val_d in transformed_val_datasets:\n",
    "    val_loader_list.append(\n",
    "        torch.utils.data.DataLoader(\n",
    "                val_d,\n",
    "                batch_size=1,\n",
    "                shuffle=True,\n",
    "                num_workers=4,\n",
    "                drop_last = False,\n",
    "            )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Evaluation  Started ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to C:\\Users\\jizhi/.cache\\torch\\hub\\checkpoints\\alexnet-owt-7be5be79.pth\n",
      "100%|██████████| 233M/233M [00:23<00:00, 10.3MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.99202, Accuracy:0.96394, Precision: 0.95215, Recall: 0.97549, F1-Score: 0.96368,Matthews Correlation Coefficient: 0.92816\n",
      "AUC: 0.99991, Accuracy:0.99519, Precision: 0.99510, Recall: 0.99510, F1-Score: 0.99510,Matthews Correlation Coefficient: 0.99038\n",
      "AUC: 0.99711, Accuracy:0.93750, Precision: 0.98901, Recall: 0.88235, F1-Score: 0.93264,Matthews Correlation Coefficient: 0.87966\n",
      "AUC: 0.99077, Accuracy:0.87500, Precision: 0.79688, Recall: 1.00000, F1-Score: 0.88696,Matthews Correlation Coefficient: 0.77551\n",
      "-------------------- Evaluation  END ------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "print(\"---------------- Evaluation  Started ---------------\")\n",
    "\n",
    "# Create or open a CSV file to store the results\n",
    "csv_file_path = \"evaluation_results.csv\"\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    # Write header\n",
    "    csv_writer.writerow(['Model Name', 'AUC','Accuracy', 'Precision', 'Recall', 'F1-Score', 'Matthews Correlation Coefficient'])\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# 指定文件夹路径\n",
    "folder_path = 'C:\\\\Users\\\\jizhi\\\\Desktop\\\\study\\\\FL\\\\federated_learning\\\\fl_results_backup_epoch50center\\\\saved_models\\\\sim\\\\fusion_models'\n",
    "\n",
    "# 获取文件夹中所有文件的名称\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# 筛选出以 .pth 结尾的文件\n",
    "pth_names = [f for f in file_names if f.endswith('.pth')]\n",
    "\n",
    "# 打印出所有以 .pth 结尾的文件的完整路径\n",
    "for pth_name in pth_names:\n",
    "    pth_file = os.path.join(folder_path, pth_name)\n",
    "    model_entity = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "    model_entity.classifier[6] = torch.nn.Linear(model_entity.classifier[6].in_features, 2)\n",
    "\n",
    "    model_entity.load_state_dict(torch.load(pth_file))\n",
    "    model_entity.to(device)\n",
    "    # 设置模型为评估模式\n",
    "    model_entity.eval()\n",
    "\n",
    "    for val_inx, val_loader in enumerate(val_loader_list):\n",
    "        if val_inx == 3:\n",
    "            label_lists = []\n",
    "            prediction_lists = []\n",
    "            pos_prob_lists = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for image, label in val_loader:\n",
    "                    image = image.to(device)\n",
    "                    model_output = model_entity(image)#模型直接输出的是对数几率\"（Logits）\"，因此我们需要应用 softmax 函数，将其转换为概率。\n",
    "\n",
    "\n",
    "                    softmax_output = F.softmax(model_output, dim=1)  # 使用softmax函数\n",
    "                    pos_prob = softmax_output[:, 1].item()  # 取第二列的值作为正例的概率\n",
    "                    pos_prob = np.float64(pos_prob)\n",
    "\n",
    "                    prediction= model_output.argmax().item()  # 取概率最大的那一列作为预测值\n",
    "                    prediction = np.int32(prediction)\n",
    "\n",
    "                    label = label.numpy()[0]  # 取出label的值#这是因为我的每一个batch_size都是1,所以label.numpy()[0]是一个numpy.int64\n",
    "                    label = np.int32(label)\n",
    "\n",
    "                    pos_prob_lists.append(pos_prob)  # 保存正例的概率,这里的pos_prob是一个float\n",
    "                    label_lists.append(label)\n",
    "                    prediction_lists.append(prediction)\n",
    "\n",
    "                label_arrays = np.array(label_lists)\n",
    "                prediction_arrays = np.array(prediction_lists)\n",
    "                pos_prob_arrays = np.array(pos_prob_lists)\n",
    "\n",
    "                # Compute Accuracy\n",
    "                accuracy = accuracy_score(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "                precision = precision_score(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "                recall = recall_score(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "                f1 = f1_score(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "                \n",
    "                # Compute Confusion Matrix\n",
    "                cm = confusion_matrix(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "                \n",
    "                # Compute Matthews Correlation Coefficient\n",
    "                mcc = matthews_corrcoef(label_arrays.tolist(), prediction_arrays.tolist())\n",
    "\n",
    "\n",
    "                label_arrays = torch.from_numpy(label_arrays).clone()\n",
    "                prediction_arrays = torch.from_numpy(prediction_arrays).clone()\n",
    "                pos_prob_arrays = torch.from_numpy(pos_prob_arrays).clone()\n",
    "\n",
    "                # Compute ROC curve and ROC area for each class\n",
    "                roc = torchmetrics.ROC(task=\"binary\")\n",
    "                fpr, tpr, thresholds = roc(pos_prob_arrays, label_arrays)\n",
    "\n",
    "                # 使用torchmetrics计算AUC\n",
    "                auc = torchmetrics.AUROC(task=\"binary\")\n",
    "                auc_value = auc(pos_prob_arrays, label_arrays)\n",
    "\n",
    "                # print(\"fpr\",fpr)\n",
    "                # print(\"tpr\",tpr)\n",
    "                # print(\"thresholds\",thresholds)\n",
    "\n",
    "                print(f'AUC: {auc_value:.5f}, Accuracy:{accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}, F1-Score: {f1:.5f},Matthews Correlation Coefficient: {mcc:.5f}')\n",
    "                #print(f'Model {pth_name}, Validation Set {val_inx}, AUC: {auc_value:.5f},Accuracy:{accuracy:.5f}')\n",
    "                # Write the evaluation results to the CSV file\n",
    "                # Open the CSV file in append mode and write the results\n",
    "                with open(csv_file_path, mode='a', newline='') as csv_file:\n",
    "                    csv_writer = csv.writer(csv_file)\n",
    "                    csv_writer.writerow([pth_name,f\"{auc_value:.5f}\", f\"{accuracy:.5f}\", f\"{precision:.5f}\", f\"{recall:.5f}\", f\"{f1:.5f}\", f\"{mcc:.5f}\"])\n",
    "print(\"-------------------- Evaluation  END ------------------------\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c33489c15c8996ec65adc4ce87c66b361d619ea135fc25c6686da34a5b53bcc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
